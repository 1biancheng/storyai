-- Migration 003: Add documents table and extend paragraphs table
-- Purpose: Document-paragraph separation architecture for three-articles integration
-- Author: Generated by design doc three-articles-implementation.md
-- Date: 2025-11-01

-- =====================================================================
-- Part 1: Create documents table (file-level metadata storage)
-- =====================================================================

CREATE TABLE IF NOT EXISTS documents (
    id SERIAL PRIMARY KEY,
    file_hash VARCHAR(64) UNIQUE NOT NULL,
    filename VARCHAR(500) NOT NULL,
    file_size INTEGER NOT NULL,
    encoding_detected VARCHAR(50),
    extraction_method VARCHAR(50),
    structure_type VARCHAR(20),
    source_lib VARCHAR(50),
    total_paragraphs INTEGER DEFAULT 0,
    meta JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT TRUE
);

-- Create indexes for documents table
CREATE INDEX IF NOT EXISTS idx_documents_file_hash ON documents(file_hash);
CREATE INDEX IF NOT EXISTS idx_documents_filename ON documents(filename);
CREATE INDEX IF NOT EXISTS idx_documents_created_at ON documents(created_at);
CREATE INDEX IF NOT EXISTS idx_documents_is_active ON documents(is_active);

COMMENT ON TABLE documents IS 'File-level metadata for uploaded documents (three-articles integration)';
COMMENT ON COLUMN documents.file_hash IS 'MD5 hash for deduplication and cache lookup';
COMMENT ON COLUMN documents.encoding_detected IS 'Detected encoding (UTF-8/GBK/Big5/etc)';
COMMENT ON COLUMN documents.extraction_method IS 'Extraction method used (cchardet+direct/textract/markitdown)';
COMMENT ON COLUMN documents.structure_type IS 'Structure preservation (plain/markdown)';
COMMENT ON COLUMN documents.source_lib IS 'Library used for extraction (cchardet/textract/markitdown)';
COMMENT ON COLUMN documents.meta IS 'Extended metadata (book_id, chapter_index, etc)';

-- =====================================================================
-- Part 2: Extend paragraphs table (add document relationship)
-- =====================================================================

-- Add new columns to paragraphs table (safe: allows NULL for existing rows)
ALTER TABLE paragraphs 
ADD COLUMN IF NOT EXISTS document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
ADD COLUMN IF NOT EXISTS encoding_source VARCHAR(50),
ADD COLUMN IF NOT EXISTS split_method VARCHAR(50),
ADD COLUMN IF NOT EXISTS char_count INTEGER;

-- Create index for foreign key
CREATE INDEX IF NOT EXISTS idx_paragraphs_document_id ON paragraphs(document_id);

COMMENT ON COLUMN paragraphs.document_id IS 'Foreign key to documents table (NULL for legacy data)';
COMMENT ON COLUMN paragraphs.encoding_source IS 'Encoding source (inherited from document or separately detected)';
COMMENT ON COLUMN paragraphs.split_method IS 'Split method (strong_punct/weak_punct/semantic_score/force_split)';
COMMENT ON COLUMN paragraphs.char_count IS 'Character count for performance tracking';

-- =====================================================================
-- Part 3: Create update trigger for documents.updated_at
-- =====================================================================

CREATE OR REPLACE FUNCTION update_documents_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS trigger_documents_updated_at ON documents;
CREATE TRIGGER trigger_documents_updated_at
BEFORE UPDATE ON documents
FOR EACH ROW
EXECUTE FUNCTION update_documents_updated_at();

-- =====================================================================
-- Part 4: Create helper views for common queries
-- =====================================================================

CREATE OR REPLACE VIEW v_documents_with_stats AS
SELECT 
    d.id,
    d.file_hash,
    d.filename,
    d.file_size,
    d.encoding_detected,
    d.extraction_method,
    d.structure_type,
    d.source_lib,
    d.total_paragraphs,
    d.created_at,
    COUNT(p.id) AS actual_paragraph_count,
    d.total_paragraphs - COUNT(p.id) AS count_mismatch
FROM documents d
LEFT JOIN paragraphs p ON p.document_id = d.id AND p.is_active = TRUE
WHERE d.is_active = TRUE
GROUP BY d.id;

COMMENT ON VIEW v_documents_with_stats IS 'Documents with actual paragraph counts and mismatch detection';

-- =====================================================================
-- Part 5: Migration verification queries (for testing)
-- =====================================================================

-- Verify documents table exists
DO $$
BEGIN
    IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'documents') THEN
        RAISE EXCEPTION 'Migration failed: documents table not created';
    END IF;
END $$;

-- Verify paragraphs columns exist
DO $$
BEGIN
    IF NOT EXISTS (
        SELECT FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'paragraphs' 
        AND column_name = 'document_id'
    ) THEN
        RAISE EXCEPTION 'Migration failed: document_id column not added to paragraphs';
    END IF;
END $$;

-- Print migration success message
DO $$
BEGIN
    RAISE NOTICE 'Migration 003 completed successfully';
    RAISE NOTICE 'Created: documents table, extended paragraphs table';
    RAISE NOTICE 'Next steps: Run data fix script if needed to link legacy paragraphs';
END $$;
-- Migration 003: Add documents table and extend paragraphs table
-- Purpose: Document-paragraph separation architecture for three-articles integration
-- Author: Generated by design doc three-articles-implementation.md
-- Date: 2025-11-01

-- =====================================================================
-- Part 1: Create documents table (file-level metadata storage)
-- =====================================================================

CREATE TABLE IF NOT EXISTS documents (
    id SERIAL PRIMARY KEY,
    file_hash VARCHAR(64) UNIQUE NOT NULL,
    filename VARCHAR(500) NOT NULL,
    file_size INTEGER NOT NULL,
    encoding_detected VARCHAR(50),
    extraction_method VARCHAR(50),
    structure_type VARCHAR(20),
    source_lib VARCHAR(50),
    total_paragraphs INTEGER DEFAULT 0,
    meta JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT TRUE
);

-- Create indexes for documents table
CREATE INDEX IF NOT EXISTS idx_documents_file_hash ON documents(file_hash);
CREATE INDEX IF NOT EXISTS idx_documents_filename ON documents(filename);
CREATE INDEX IF NOT EXISTS idx_documents_created_at ON documents(created_at);
CREATE INDEX IF NOT EXISTS idx_documents_is_active ON documents(is_active);

COMMENT ON TABLE documents IS 'File-level metadata for uploaded documents (three-articles integration)';
COMMENT ON COLUMN documents.file_hash IS 'MD5 hash for deduplication and cache lookup';
COMMENT ON COLUMN documents.encoding_detected IS 'Detected encoding (UTF-8/GBK/Big5/etc)';
COMMENT ON COLUMN documents.extraction_method IS 'Extraction method used (cchardet+direct/textract/markitdown)';
COMMENT ON COLUMN documents.structure_type IS 'Structure preservation (plain/markdown)';
COMMENT ON COLUMN documents.source_lib IS 'Library used for extraction (cchardet/textract/markitdown)';
COMMENT ON COLUMN documents.meta IS 'Extended metadata (book_id, chapter_index, etc)';

-- =====================================================================
-- Part 2: Extend paragraphs table (add document relationship)
-- =====================================================================

-- Add new columns to paragraphs table (safe: allows NULL for existing rows)
ALTER TABLE paragraphs 
ADD COLUMN IF NOT EXISTS document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
ADD COLUMN IF NOT EXISTS encoding_source VARCHAR(50),
ADD COLUMN IF NOT EXISTS split_method VARCHAR(50),
ADD COLUMN IF NOT EXISTS char_count INTEGER;

-- Create index for foreign key
CREATE INDEX IF NOT EXISTS idx_paragraphs_document_id ON paragraphs(document_id);

COMMENT ON COLUMN paragraphs.document_id IS 'Foreign key to documents table (NULL for legacy data)';
COMMENT ON COLUMN paragraphs.encoding_source IS 'Encoding source (inherited from document or separately detected)';
COMMENT ON COLUMN paragraphs.split_method IS 'Split method (strong_punct/weak_punct/semantic_score/force_split)';
COMMENT ON COLUMN paragraphs.char_count IS 'Character count for performance tracking';

-- =====================================================================
-- Part 3: Create update trigger for documents.updated_at
-- =====================================================================

CREATE OR REPLACE FUNCTION update_documents_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS trigger_documents_updated_at ON documents;
CREATE TRIGGER trigger_documents_updated_at
BEFORE UPDATE ON documents
FOR EACH ROW
EXECUTE FUNCTION update_documents_updated_at();

-- =====================================================================
-- Part 4: Create helper views for common queries
-- =====================================================================

CREATE OR REPLACE VIEW v_documents_with_stats AS
SELECT 
    d.id,
    d.file_hash,
    d.filename,
    d.file_size,
    d.encoding_detected,
    d.extraction_method,
    d.structure_type,
    d.source_lib,
    d.total_paragraphs,
    d.created_at,
    COUNT(p.id) AS actual_paragraph_count,
    d.total_paragraphs - COUNT(p.id) AS count_mismatch
FROM documents d
LEFT JOIN paragraphs p ON p.document_id = d.id AND p.is_active = TRUE
WHERE d.is_active = TRUE
GROUP BY d.id;

COMMENT ON VIEW v_documents_with_stats IS 'Documents with actual paragraph counts and mismatch detection';

-- =====================================================================
-- Part 5: Migration verification queries (for testing)
-- =====================================================================

-- Verify documents table exists
DO $$
BEGIN
    IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'documents') THEN
        RAISE EXCEPTION 'Migration failed: documents table not created';
    END IF;
END $$;

-- Verify paragraphs columns exist
DO $$
BEGIN
    IF NOT EXISTS (
        SELECT FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'paragraphs' 
        AND column_name = 'document_id'
    ) THEN
        RAISE EXCEPTION 'Migration failed: document_id column not added to paragraphs';
    END IF;
END $$;

-- Print migration success message
DO $$
BEGIN
    RAISE NOTICE 'Migration 003 completed successfully';
    RAISE NOTICE 'Created: documents table, extended paragraphs table';
    RAISE NOTICE 'Next steps: Run data fix script if needed to link legacy paragraphs';
END $$;
