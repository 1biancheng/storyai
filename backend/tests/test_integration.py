"""
é›†æˆæµ‹è¯•: æ‹†ä¹¦å·¥å…·ä¼˜åŒ–ç³»ç»Ÿ
æµ‹è¯•æ•´ä¸ªç«¯åˆ°ç«¯æµç¨‹

æµ‹è¯•è¦†ç›–:
1. æ®µè½å¢å¼ºå™¨: å…³é”®è¯æå–ã€æƒé‡åç½®åˆå§‹åŒ–
2. å…¬å¼ç”Ÿæˆå™¨: æ€»å…¬å¼æå–ã€å¤šç»´åº¦å…¬å¼
3. å…¬å¼è¿˜åŸå¼•æ“: å‰å‘æ¨ç†è¿˜åŸ
4. å…³é”®è¯RAG: ç¨€ç–æ¿€æ´»ã€å‘é‡ç²¾æ’ã€æ··åˆæ£€ç´¢
5. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨: Qå€¼æ›´æ–°ã€UCBé€‰æ‹©ã€ç”Ÿæˆå†…å®¹å…¥åº“

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024-01-15
"""

import asyncio
import sys
import os
from pathlib import Path
import json
import numpy as np

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

# æµ‹è¯•ç”¨çš„æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ± 
class MockDBPool:
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ± """
    
    async def acquire(self):
        return MockDBConnection()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


class MockDBConnection:
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥"""
    
    async def fetch(self, query, *args):
        # è¿”å›æ¨¡æ‹Ÿæ®µè½æ•°æ®
        return [
            {
                'id': 'para_001',
                'content': 'æœˆå…‰æ´’åœ¨é™è°§çš„å±±è°·ä¸­,å¾®é£æ‹‚è¿‡æ¾æ—,å‘å‡ºé˜µé˜µä½åŸã€‚',
                'embedding': np.random.randn(1536).tolist(),
                'enhanced_embedding': np.random.randn(1536).tolist(),
                'meta': {
                    'keywords': ['æœˆå…‰', 'å±±è°·', 'æ¾æ—'],
                    'q_values': {'query_cluster_0': 0.75},
                    'visit_count': {'query_cluster_0': 5}
                },
                'sequence_weight': 1.2
            },
            {
                'id': 'para_002',
                'content': 'ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚',
                'embedding': np.random.randn(1536).tolist(),
                'enhanced_embedding': np.random.randn(1536).tolist(),
                'meta': {
                    'keywords': ['å±±å·…', 'äº‘æµ·', 'æ„Ÿæ…¨'],
                    'q_values': {'query_cluster_0': 0.82},
                    'visit_count': {'query_cluster_0': 8}
                },
                'sequence_weight': 1.5
            }
        ]
    
    async def fetchrow(self, query, *args):
        rows = await self.fetch(query, *args)
        return rows[0] if rows else None
    
    async def execute(self, query, *args):
        return None
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass


async def test_paragraph_enhancer():
    """æµ‹è¯•1: æ®µè½å¢å¼ºå™¨"""
    print("\n=== æµ‹è¯•1: æ®µè½å¢å¼ºå™¨ ===")
    
    try:
        from services.paragraph_enhancer import (
            extract_keywords,
            extract_idioms,
            initialize_sequence_weight,
            initialize_paragraph_bias,
            compute_enhanced_embedding
        )
        
        # æµ‹è¯•å…³é”®è¯æå–
        text = "ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚ç ´é‡œæ²‰èˆŸ,èƒŒæ°´ä¸€æˆ˜!"
        keywords = extract_keywords(text, topK=5)
        print(f"âœ“ å…³é”®è¯æå–: {keywords}")
        assert len(keywords) > 0, "å…³é”®è¯æå–å¤±è´¥"
        
        # æµ‹è¯•æˆè¯­æ£€æµ‹
        idioms = extract_idioms(text)
        print(f"âœ“ æˆè¯­æ£€æµ‹: {idioms}")
        assert 'ç ´é‡œæ²‰èˆŸ' in idioms, "æˆè¯­æ£€æµ‹å¤±è´¥"
        
        # æµ‹è¯•æƒé‡åˆå§‹åŒ–
        weight = initialize_sequence_weight(text, is_chapter_start=True)
        print(f"âœ“ åºåˆ—æƒé‡: {weight}")
        assert 0.5 <= weight <= 2.0, "æƒé‡è¶…å‡ºèŒƒå›´"
        
        # æµ‹è¯•åç½®åˆå§‹åŒ–
        bias = initialize_paragraph_bias(
            paragraph=text,
            global_position=0.5,
            emotion_intensity=0.7,
            keywords=keywords
        )
        print(f"âœ“ åç½®å‘é‡: shape={bias.shape}, mean={bias.mean():.4f}")
        assert bias.shape == (1536,), "åç½®ç»´åº¦é”™è¯¯"
        
        # æµ‹è¯•å¢å¼ºå‘é‡è®¡ç®—
        original_embedding = np.random.randn(1536)
        enhanced = compute_enhanced_embedding(original_embedding, weight, bias)
        print(f"âœ“ å¢å¼ºå‘é‡: shape={enhanced.shape}")
        assert enhanced.shape == (1536,), "å¢å¼ºå‘é‡ç»´åº¦é”™è¯¯"
        
        print("âœ… æ®µè½å¢å¼ºå™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ æ®µè½å¢å¼ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_formula_generator():
    """æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨"""
    print("\n=== æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨ ===")
    
    try:
        from services.formula_generator import FormulaGenerator
        
        # æ¨¡æ‹Ÿæ®µè½æ•°æ®
        paragraphs = [
            {
                "id": "para_001",
                "content": "æœˆå…‰æ´’åœ¨é™è°§çš„å±±è°·ä¸­,å¾®é£æ‹‚è¿‡æ¾æ—,å‘å‡ºé˜µé˜µä½åŸã€‚",
                "embedding": np.random.randn(1536).tolist(),
                "sequence_weight": 1.2,
                "paragraph_bias": np.random.randn(1536).tolist(),
                "meta": {
                    "keywords": ["æœˆå…‰", "å±±è°·", "æ¾æ—"],
                    "chapter_index": 0,
                    "paragraph_index": 0,
                    "global_position": 0.0
                }
            },
            {
                "id": "para_002",
                "content": "ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚",
                "embedding": np.random.randn(1536).tolist(),
                "sequence_weight": 1.5,
                "paragraph_bias": np.random.randn(1536).tolist(),
                "meta": {
                    "keywords": ["å±±å·…", "äº‘æµ·", "æ„Ÿæ…¨"],
                    "chapter_index": 0,
                    "paragraph_index": 1,
                    "global_position": 0.5
                }
            }
        ]
        
        generator = FormulaGenerator()
        
        # ç”Ÿæˆæ€»å…¬å¼
        master_formula = generator.generate_master_formula(
            paragraphs=paragraphs,
            book_id="test_book_001",
            book_title="æµ‹è¯•å°è¯´"
        )
        
        print(f"âœ“ æ€»å…¬å¼ID: {master_formula['formula_id']}")
        print(f"âœ“ ä¹¦ç±ID: {master_formula['book_id']}")
        print(f"âœ“ æ®µè½åºåˆ—é•¿åº¦: {len(master_formula['paragraph_sequence']['sequence'])}")
        print(f"âœ“ æ€»æ®µè½æ•°: {master_formula['paragraph_sequence']['total_paragraphs']}")
        
        # éªŒè¯ç»“æ„
        assert 'formula_id' in master_formula, "ç¼ºå°‘formula_id"
        assert 'paragraph_sequence' in master_formula, "ç¼ºå°‘æ®µè½åºåˆ—"
        assert 'plot_formula' in master_formula, "ç¼ºå°‘å‰§æƒ…å…¬å¼"
        assert 'description_formula' in master_formula, "ç¼ºå°‘æå†™å…¬å¼"
        
        print("âœ… å…¬å¼ç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…¬å¼ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_formula_restoration():
    """æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“"""
    print("\n=== æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“ ===")
    
    try:
        from services.formula_restoration import FormulaRestorationEngine
        
        # åˆ›å»ºæ¨¡æ‹Ÿå…¬å¼
        mock_formula = {
            "formula_id": "formula_test_001",
            "book_id": "test_book_001",
            "paragraph_sequence": {
                "total_paragraphs": 2,
                "sequence": [
                    {"index": 0, "paragraph_id": "para_001", "weight": 1.2},
                    {"index": 1, "paragraph_id": "para_002", "weight": 1.5}
                ]
            }
        }
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        engine = FormulaRestorationEngine(db_pool)
        
        # è¿˜åŸå°è¯´(ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®,ä¸å®é™…æŸ¥è¯¢æ•°æ®åº“)
        # æ³¨æ„:è¿™é‡Œåªæµ‹è¯•åŸºç¡€é€»è¾‘,å®é™…æ•°æ®åº“æŸ¥è¯¢ä¼šè¢«mock
        
        print("âœ“ å…¬å¼è¿˜åŸå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"âœ“ æµ‹è¯•å…¬å¼æ®µè½æ•°: {len(mock_formula['paragraph_sequence']['sequence'])}")
        
        print("âœ… å…¬å¼è¿˜åŸå¼•æ“æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…¬å¼è¿˜åŸå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_keyword_rag():
    """æµ‹è¯•4: å…³é”®è¯RAG"""
    print("\n=== æµ‹è¯•4: å…³é”®è¯RAG ===")
    
    try:
        from services.keyword_rag import KeywordRAG
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        rag = KeywordRAG(db_pool)
        
        # æ„å»ºå€’æ’ç´¢å¼•
        await rag.build_inverted_index()
        print(f"âœ“ å€’æ’ç´¢å¼•æ„å»ºå®Œæˆ: {len(rag.inverted_index)} ä¸ªå…³é”®è¯")
        
        # æµ‹è¯•ç¨€ç–æ¿€æ´»
        candidate_pids = rag.keyword_activate("å±±å·… äº‘æµ·", top_k=10)
        print(f"âœ“ ç¨€ç–æ¿€æ´»ç»“æœ: {len(candidate_pids)} ä¸ªå€™é€‰æ®µè½")
        
        # æµ‹è¯•å‘é‡ç²¾æ’
        query_vec = np.random.randn(1536).tolist()
        if candidate_pids:
            reranked = await rag.vector_rerank(
                query_embedding=query_vec,
                candidate_pids=candidate_pids,
                top_n=5
            )
            print(f"âœ“ å‘é‡ç²¾æ’ç»“æœ: {len(reranked)} ä¸ªæ®µè½")
        
        print("âœ… å…³é”®è¯RAGæµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…³é”®è¯RAGæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_rl_optimizer():
    """æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨"""
    print("\n=== æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨ ===")
    
    try:
        from services.rl_optimizer import ReinforcementLearningOptimizer
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        rl = ReinforcementLearningOptimizer(db_pool, num_clusters=10)
        
        # åˆå§‹åŒ–æŸ¥è¯¢èšç±»
        await rl.initialize_query_clusters(sample_size=50)
        print(f"âœ“ æŸ¥è¯¢èšç±»åˆå§‹åŒ–å®Œæˆ: {rl.num_clusters} ä¸ªç°‡")
        
        # æµ‹è¯•æŸ¥è¯¢èšç±»æ˜ å°„
        query_vec = np.random.randn(1536)
        cluster = rl.get_query_cluster(query_vec)
        print(f"âœ“ æŸ¥è¯¢èšç±»æ˜ å°„: {cluster}")
        assert cluster.startswith("query_cluster_"), "èšç±»IDæ ¼å¼é”™è¯¯"
        
        # æµ‹è¯•å¥–åŠ±è®¡ç®—
        reward = await rl.calculate_reward(
            spliced_content="æµ‹è¯•å†…å®¹",
            contexts=["ä¸Šä¸‹æ–‡1", "ä¸Šä¸‹æ–‡2"],
            llm_score=0.85,
            user_feedback="thumbs_up"
        )
        print(f"âœ“ å¥–åŠ±è®¡ç®—: {reward:.3f}")
        assert 0 <= reward <= 1, "å¥–åŠ±å€¼è¶…å‡ºèŒƒå›´"
        
        # æµ‹è¯•å…¥åº“å†³ç­–
        should_store, quality = await rl.should_store_generated_content(
            reward=0.85,
            spliced_content="è¿™æ˜¯ä¸€æ®µé«˜è´¨é‡çš„ç”Ÿæˆå†…å®¹,æœ‰è¶³å¤Ÿçš„é•¿åº¦å’Œè¯­ä¹‰å®Œæ•´æ€§ã€‚"
        )
        print(f"âœ“ å…¥åº“å†³ç­–: should_store={should_store}, quality={quality}")
        assert quality == "high", "è´¨é‡åˆ¤æ–­é”™è¯¯"
        
        print("âœ… å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("å¼€å§‹æ‰§è¡Œæ‹†ä¹¦å·¥å…·ä¼˜åŒ–ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("="*60)
    
    results = {}
    
    # æµ‹è¯•1: æ®µè½å¢å¼ºå™¨
    results['paragraph_enhancer'] = await test_paragraph_enhancer()
    
    # æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨
    results['formula_generator'] = await test_formula_generator()
    
    # æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“
    results['formula_restoration'] = await test_formula_restoration()
    
    # æµ‹è¯•4: å…³é”®è¯RAG
    results['keyword_rag'] = await test_keyword_rag()
    
    # æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨
    results['rl_optimizer'] = await test_rl_optimizer()
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    
    total = len(results)
    passed = sum(1 for r in results.values() if r)
    failed = total - passed
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name.ljust(25)}: {status}")
    
    print("-" * 60)
    print(f"æ€»è®¡: {total} ä¸ªæµ‹è¯•, {passed} ä¸ªé€šè¿‡, {failed} ä¸ªå¤±è´¥")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥,è¯·æ£€æŸ¥æ—¥å¿—")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)
"""
é›†æˆæµ‹è¯•: æ‹†ä¹¦å·¥å…·ä¼˜åŒ–ç³»ç»Ÿ
æµ‹è¯•æ•´ä¸ªç«¯åˆ°ç«¯æµç¨‹

æµ‹è¯•è¦†ç›–:
1. æ®µè½å¢å¼ºå™¨: å…³é”®è¯æå–ã€æƒé‡åç½®åˆå§‹åŒ–
2. å…¬å¼ç”Ÿæˆå™¨: æ€»å…¬å¼æå–ã€å¤šç»´åº¦å…¬å¼
3. å…¬å¼è¿˜åŸå¼•æ“: å‰å‘æ¨ç†è¿˜åŸ
4. å…³é”®è¯RAG: ç¨€ç–æ¿€æ´»ã€å‘é‡ç²¾æ’ã€æ··åˆæ£€ç´¢
5. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨: Qå€¼æ›´æ–°ã€UCBé€‰æ‹©ã€ç”Ÿæˆå†…å®¹å…¥åº“

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024-01-15
"""

import asyncio
import sys
import os
from pathlib import Path
import json
import numpy as np

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

# æµ‹è¯•ç”¨çš„æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ± 
class MockDBPool:
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ± """
    
    async def acquire(self):
        return MockDBConnection()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


class MockDBConnection:
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥"""
    
    async def fetch(self, query, *args):
        # è¿”å›æ¨¡æ‹Ÿæ®µè½æ•°æ®
        return [
            {
                'id': 'para_001',
                'content': 'æœˆå…‰æ´’åœ¨é™è°§çš„å±±è°·ä¸­,å¾®é£æ‹‚è¿‡æ¾æ—,å‘å‡ºé˜µé˜µä½åŸã€‚',
                'embedding': np.random.randn(1536).tolist(),
                'enhanced_embedding': np.random.randn(1536).tolist(),
                'meta': {
                    'keywords': ['æœˆå…‰', 'å±±è°·', 'æ¾æ—'],
                    'q_values': {'query_cluster_0': 0.75},
                    'visit_count': {'query_cluster_0': 5}
                },
                'sequence_weight': 1.2
            },
            {
                'id': 'para_002',
                'content': 'ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚',
                'embedding': np.random.randn(1536).tolist(),
                'enhanced_embedding': np.random.randn(1536).tolist(),
                'meta': {
                    'keywords': ['å±±å·…', 'äº‘æµ·', 'æ„Ÿæ…¨'],
                    'q_values': {'query_cluster_0': 0.82},
                    'visit_count': {'query_cluster_0': 8}
                },
                'sequence_weight': 1.5
            }
        ]
    
    async def fetchrow(self, query, *args):
        rows = await self.fetch(query, *args)
        return rows[0] if rows else None
    
    async def execute(self, query, *args):
        return None
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass


async def test_paragraph_enhancer():
    """æµ‹è¯•1: æ®µè½å¢å¼ºå™¨"""
    print("\n=== æµ‹è¯•1: æ®µè½å¢å¼ºå™¨ ===")
    
    try:
        from services.paragraph_enhancer import (
            extract_keywords,
            extract_idioms,
            initialize_sequence_weight,
            initialize_paragraph_bias,
            compute_enhanced_embedding
        )
        
        # æµ‹è¯•å…³é”®è¯æå–
        text = "ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚ç ´é‡œæ²‰èˆŸ,èƒŒæ°´ä¸€æˆ˜!"
        keywords = extract_keywords(text, topK=5)
        print(f"âœ“ å…³é”®è¯æå–: {keywords}")
        assert len(keywords) > 0, "å…³é”®è¯æå–å¤±è´¥"
        
        # æµ‹è¯•æˆè¯­æ£€æµ‹
        idioms = extract_idioms(text)
        print(f"âœ“ æˆè¯­æ£€æµ‹: {idioms}")
        assert 'ç ´é‡œæ²‰èˆŸ' in idioms, "æˆè¯­æ£€æµ‹å¤±è´¥"
        
        # æµ‹è¯•æƒé‡åˆå§‹åŒ–
        weight = initialize_sequence_weight(text, is_chapter_start=True)
        print(f"âœ“ åºåˆ—æƒé‡: {weight}")
        assert 0.5 <= weight <= 2.0, "æƒé‡è¶…å‡ºèŒƒå›´"
        
        # æµ‹è¯•åç½®åˆå§‹åŒ–
        bias = initialize_paragraph_bias(
            paragraph=text,
            global_position=0.5,
            emotion_intensity=0.7,
            keywords=keywords
        )
        print(f"âœ“ åç½®å‘é‡: shape={bias.shape}, mean={bias.mean():.4f}")
        assert bias.shape == (1536,), "åç½®ç»´åº¦é”™è¯¯"
        
        # æµ‹è¯•å¢å¼ºå‘é‡è®¡ç®—
        original_embedding = np.random.randn(1536)
        enhanced = compute_enhanced_embedding(original_embedding, weight, bias)
        print(f"âœ“ å¢å¼ºå‘é‡: shape={enhanced.shape}")
        assert enhanced.shape == (1536,), "å¢å¼ºå‘é‡ç»´åº¦é”™è¯¯"
        
        print("âœ… æ®µè½å¢å¼ºå™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ æ®µè½å¢å¼ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_formula_generator():
    """æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨"""
    print("\n=== æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨ ===")
    
    try:
        from services.formula_generator import FormulaGenerator
        
        # æ¨¡æ‹Ÿæ®µè½æ•°æ®
        paragraphs = [
            {
                "id": "para_001",
                "content": "æœˆå…‰æ´’åœ¨é™è°§çš„å±±è°·ä¸­,å¾®é£æ‹‚è¿‡æ¾æ—,å‘å‡ºé˜µé˜µä½åŸã€‚",
                "embedding": np.random.randn(1536).tolist(),
                "sequence_weight": 1.2,
                "paragraph_bias": np.random.randn(1536).tolist(),
                "meta": {
                    "keywords": ["æœˆå…‰", "å±±è°·", "æ¾æ—"],
                    "chapter_index": 0,
                    "paragraph_index": 0,
                    "global_position": 0.0
                }
            },
            {
                "id": "para_002",
                "content": "ä»–ç‹¬è‡ªç«™åœ¨å±±å·…,æœ›ç€äº‘æµ·ç¿»æ¶Œ,å¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚",
                "embedding": np.random.randn(1536).tolist(),
                "sequence_weight": 1.5,
                "paragraph_bias": np.random.randn(1536).tolist(),
                "meta": {
                    "keywords": ["å±±å·…", "äº‘æµ·", "æ„Ÿæ…¨"],
                    "chapter_index": 0,
                    "paragraph_index": 1,
                    "global_position": 0.5
                }
            }
        ]
        
        generator = FormulaGenerator()
        
        # ç”Ÿæˆæ€»å…¬å¼
        master_formula = generator.generate_master_formula(
            paragraphs=paragraphs,
            book_id="test_book_001",
            book_title="æµ‹è¯•å°è¯´"
        )
        
        print(f"âœ“ æ€»å…¬å¼ID: {master_formula['formula_id']}")
        print(f"âœ“ ä¹¦ç±ID: {master_formula['book_id']}")
        print(f"âœ“ æ®µè½åºåˆ—é•¿åº¦: {len(master_formula['paragraph_sequence']['sequence'])}")
        print(f"âœ“ æ€»æ®µè½æ•°: {master_formula['paragraph_sequence']['total_paragraphs']}")
        
        # éªŒè¯ç»“æ„
        assert 'formula_id' in master_formula, "ç¼ºå°‘formula_id"
        assert 'paragraph_sequence' in master_formula, "ç¼ºå°‘æ®µè½åºåˆ—"
        assert 'plot_formula' in master_formula, "ç¼ºå°‘å‰§æƒ…å…¬å¼"
        assert 'description_formula' in master_formula, "ç¼ºå°‘æå†™å…¬å¼"
        
        print("âœ… å…¬å¼ç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…¬å¼ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_formula_restoration():
    """æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“"""
    print("\n=== æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“ ===")
    
    try:
        from services.formula_restoration import FormulaRestorationEngine
        
        # åˆ›å»ºæ¨¡æ‹Ÿå…¬å¼
        mock_formula = {
            "formula_id": "formula_test_001",
            "book_id": "test_book_001",
            "paragraph_sequence": {
                "total_paragraphs": 2,
                "sequence": [
                    {"index": 0, "paragraph_id": "para_001", "weight": 1.2},
                    {"index": 1, "paragraph_id": "para_002", "weight": 1.5}
                ]
            }
        }
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        engine = FormulaRestorationEngine(db_pool)
        
        # è¿˜åŸå°è¯´(ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®,ä¸å®é™…æŸ¥è¯¢æ•°æ®åº“)
        # æ³¨æ„:è¿™é‡Œåªæµ‹è¯•åŸºç¡€é€»è¾‘,å®é™…æ•°æ®åº“æŸ¥è¯¢ä¼šè¢«mock
        
        print("âœ“ å…¬å¼è¿˜åŸå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"âœ“ æµ‹è¯•å…¬å¼æ®µè½æ•°: {len(mock_formula['paragraph_sequence']['sequence'])}")
        
        print("âœ… å…¬å¼è¿˜åŸå¼•æ“æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…¬å¼è¿˜åŸå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_keyword_rag():
    """æµ‹è¯•4: å…³é”®è¯RAG"""
    print("\n=== æµ‹è¯•4: å…³é”®è¯RAG ===")
    
    try:
        from services.keyword_rag import KeywordRAG
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        rag = KeywordRAG(db_pool)
        
        # æ„å»ºå€’æ’ç´¢å¼•
        await rag.build_inverted_index()
        print(f"âœ“ å€’æ’ç´¢å¼•æ„å»ºå®Œæˆ: {len(rag.inverted_index)} ä¸ªå…³é”®è¯")
        
        # æµ‹è¯•ç¨€ç–æ¿€æ´»
        candidate_pids = rag.keyword_activate("å±±å·… äº‘æµ·", top_k=10)
        print(f"âœ“ ç¨€ç–æ¿€æ´»ç»“æœ: {len(candidate_pids)} ä¸ªå€™é€‰æ®µè½")
        
        # æµ‹è¯•å‘é‡ç²¾æ’
        query_vec = np.random.randn(1536).tolist()
        if candidate_pids:
            reranked = await rag.vector_rerank(
                query_embedding=query_vec,
                candidate_pids=candidate_pids,
                top_n=5
            )
            print(f"âœ“ å‘é‡ç²¾æ’ç»“æœ: {len(reranked)} ä¸ªæ®µè½")
        
        print("âœ… å…³é”®è¯RAGæµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å…³é”®è¯RAGæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_rl_optimizer():
    """æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨"""
    print("\n=== æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨ ===")
    
    try:
        from services.rl_optimizer import ReinforcementLearningOptimizer
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“
        db_pool = MockDBPool()
        rl = ReinforcementLearningOptimizer(db_pool, num_clusters=10)
        
        # åˆå§‹åŒ–æŸ¥è¯¢èšç±»
        await rl.initialize_query_clusters(sample_size=50)
        print(f"âœ“ æŸ¥è¯¢èšç±»åˆå§‹åŒ–å®Œæˆ: {rl.num_clusters} ä¸ªç°‡")
        
        # æµ‹è¯•æŸ¥è¯¢èšç±»æ˜ å°„
        query_vec = np.random.randn(1536)
        cluster = rl.get_query_cluster(query_vec)
        print(f"âœ“ æŸ¥è¯¢èšç±»æ˜ å°„: {cluster}")
        assert cluster.startswith("query_cluster_"), "èšç±»IDæ ¼å¼é”™è¯¯"
        
        # æµ‹è¯•å¥–åŠ±è®¡ç®—
        reward = await rl.calculate_reward(
            spliced_content="æµ‹è¯•å†…å®¹",
            contexts=["ä¸Šä¸‹æ–‡1", "ä¸Šä¸‹æ–‡2"],
            llm_score=0.85,
            user_feedback="thumbs_up"
        )
        print(f"âœ“ å¥–åŠ±è®¡ç®—: {reward:.3f}")
        assert 0 <= reward <= 1, "å¥–åŠ±å€¼è¶…å‡ºèŒƒå›´"
        
        # æµ‹è¯•å…¥åº“å†³ç­–
        should_store, quality = await rl.should_store_generated_content(
            reward=0.85,
            spliced_content="è¿™æ˜¯ä¸€æ®µé«˜è´¨é‡çš„ç”Ÿæˆå†…å®¹,æœ‰è¶³å¤Ÿçš„é•¿åº¦å’Œè¯­ä¹‰å®Œæ•´æ€§ã€‚"
        )
        print(f"âœ“ å…¥åº“å†³ç­–: should_store={should_store}, quality={quality}")
        assert quality == "high", "è´¨é‡åˆ¤æ–­é”™è¯¯"
        
        print("âœ… å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("å¼€å§‹æ‰§è¡Œæ‹†ä¹¦å·¥å…·ä¼˜åŒ–ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("="*60)
    
    results = {}
    
    # æµ‹è¯•1: æ®µè½å¢å¼ºå™¨
    results['paragraph_enhancer'] = await test_paragraph_enhancer()
    
    # æµ‹è¯•2: å…¬å¼ç”Ÿæˆå™¨
    results['formula_generator'] = await test_formula_generator()
    
    # æµ‹è¯•3: å…¬å¼è¿˜åŸå¼•æ“
    results['formula_restoration'] = await test_formula_restoration()
    
    # æµ‹è¯•4: å…³é”®è¯RAG
    results['keyword_rag'] = await test_keyword_rag()
    
    # æµ‹è¯•5: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨
    results['rl_optimizer'] = await test_rl_optimizer()
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    
    total = len(results)
    passed = sum(1 for r in results.values() if r)
    failed = total - passed
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name.ljust(25)}: {status}")
    
    print("-" * 60)
    print(f"æ€»è®¡: {total} ä¸ªæµ‹è¯•, {passed} ä¸ªé€šè¿‡, {failed} ä¸ªå¤±è´¥")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥,è¯·æ£€æŸ¥æ—¥å¿—")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)
